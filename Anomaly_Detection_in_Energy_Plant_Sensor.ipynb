{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": [],
      "name": "Anomaly Detection in Energy Plant Sensor ",
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 128579,
          "databundleVersionId": 15414521,
          "sourceType": "competition"
        },
        {
          "sourceId": 14623154,
          "sourceType": "datasetVersion",
          "datasetId": 9340537
        }
      ],
      "dockerImageVersionId": 31259,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/princetech89/Anomaly-Detection-in-Energy-Plant-Sensors/blob/main/Anomaly_Detection_in_Energy_Plant_Sensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n"
      ],
      "metadata": {
        "id": "_vndN0KUJUVa"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "ana_verse_2_0_h_path = kagglehub.competition_download('ana-verse-2-0-h')\n",
        "princechourasiya_competition_data_path = kagglehub.dataset_download('princechourasiya/competition-data')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "CyulaakHJUVi"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Problem Statement & Objective**\n",
        "\n",
        "The objective is to predict whether a given set of sensor readings corresponds to an anomaly (target = 1) or normal operation (target = 0) in an energy manufacturing plant.\n",
        "\n",
        "This is a binary classification problem using time-series-like tabular data.\n",
        "\n",
        "**Evaluation Focus**\n",
        "Models are evaluated using:\n",
        "Accuracy\n",
        "Precision\n",
        "Recall\n",
        "F1 Score (primary due to class imbalance)"
      ],
      "metadata": {
        "id": "VC3qHv7P3fMa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Import Libraries**"
      ],
      "metadata": {
        "id": "BdLjqsMz4zNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code !pip install catboost uses the pip package installer to download and install the catboost library. This is a common way to install Python packages in Colab notebooks, allowing you to use the library's functionalities in your code."
      ],
      "metadata": {
        "id": "EX8eUejg5vkI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "AX2JojU_5eRp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:50:32.559304Z",
          "iopub.execute_input": "2026-01-26T20:50:32.559637Z",
          "iopub.status.idle": "2026-01-26T20:50:38.172581Z",
          "shell.execute_reply.started": "2026-01-26T20:50:32.559609Z",
          "shell.execute_reply": "2026-01-26T20:50:38.171261Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    classification_report\n",
        ")\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "OSZ2Z8rD3Oc9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:50:38.175453Z",
          "iopub.execute_input": "2026-01-26T20:50:38.175755Z",
          "iopub.status.idle": "2026-01-26T20:50:48.155041Z",
          "shell.execute_reply.started": "2026-01-26T20:50:38.175721Z",
          "shell.execute_reply": "2026-01-26T20:50:48.154187Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Load Dataset**"
      ],
      "metadata": {
        "id": "j0wyvwFu57cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv(\"/kaggle/input/competition-data/train.csv\")\n",
        "test = pd.read_csv(\"/kaggle/input/competition-data/test.csv\")\n",
        "\n",
        "train['Date'] = pd.to_datetime(train['Date'])\n",
        "test['Date'] = pd.to_datetime(test['Date'])\n",
        "\n",
        "train.head()"
      ],
      "metadata": {
        "id": "lMeurpM-6DrX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:50:48.156022Z",
          "iopub.execute_input": "2026-01-26T20:50:48.156619Z",
          "iopub.status.idle": "2026-01-26T20:50:51.452813Z",
          "shell.execute_reply.started": "2026-01-26T20:50:48.156593Z",
          "shell.execute_reply": "2026-01-26T20:50:51.451937Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()\n",
        "train.describe()"
      ],
      "metadata": {
        "id": "vmpRDtuC7yeJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:50:51.454098Z",
          "iopub.execute_input": "2026-01-26T20:50:51.454458Z",
          "iopub.status.idle": "2026-01-26T20:50:51.863635Z",
          "shell.execute_reply.started": "2026-01-26T20:50:51.454424Z",
          "shell.execute_reply": "2026-01-26T20:50:51.862672Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data Size:** The dataset contains 109,049 entries and 7\n",
        "columns.\n",
        "\n",
        "**Missing Values:** One missing value is present in columns X2, X3, X4, X5, and target.\n",
        "\n",
        "**Data Types:** The 'Date' column is correctly parsed as datetime, while features X1 through X5 and the target are float64.\n",
        "\n",
        "**Class Imbalance:** The target variable shows a significant class imbalance, with only about 2.1% of the entries representing anomalies (target = 1).\n",
        "\n",
        "**Potential Outliers/Errors:** Columns X3 and X4 exhibit extremely large maximum values and standard deviations, suggesting the presence of severe outliers or potential data entry errors that warrant further investigation."
      ],
      "metadata": {
        "id": "Yksx6Zr58zRv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Target Distribution (Class Imbalance)**"
      ],
      "metadata": {
        "id": "NNrQsodv7LN7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is highly imbalanced with anomalies being rare.\n",
        "Therefore F1-score and recall are emphasized, and class-weighting / resampling techniques are used."
      ],
      "metadata": {
        "id": "KOUClUSZ7qdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train['target'].value_counts()\n",
        "\n",
        "train['target'].value_counts(normalize=True).plot(kind='bar')\n",
        "plt.title(\"Target Class Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X75405KE7J7W",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:50:51.864652Z",
          "iopub.execute_input": "2026-01-26T20:50:51.865031Z",
          "iopub.status.idle": "2026-01-26T20:50:52.146557Z",
          "shell.execute_reply.started": "2026-01-26T20:50:51.865005Z",
          "shell.execute_reply": "2026-01-26T20:50:52.145712Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Class Imbalance:** A tall bar for 0.0 and a very short bar for 1.0. This visually confirms the significant class imbalance, where normal operations vastly outnumber anomalies.\n",
        "\n",
        "**Percentage of Anomalies:** The exact percentage for 1.0 (which we noted as approximately 2.1% earlier) will be clearly visible or inferable from the bar's height. This highlights why traditional accuracy might be misleading, and why metrics like F1-score and recall are more appropriate."
      ],
      "metadata": {
        "id": "QQU2hiAN-mpL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. Missing Values & Outliers**"
      ],
      "metadata": {
        "id": "-_swL-Qr_K_T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*  Missing Values"
      ],
      "metadata": {
        "id": "VUSBMIbY_WU_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()"
      ],
      "metadata": {
        "id": "dq-T09bv_Smx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:50:52.147636Z",
          "iopub.execute_input": "2026-01-26T20:50:52.147921Z",
          "iopub.status.idle": "2026-01-26T20:50:52.171842Z",
          "shell.execute_reply.started": "2026-01-26T20:50:52.147896Z",
          "shell.execute_reply": "2026-01-26T20:50:52.171125Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Date and X1:** Both have 0 missing values, indicating they are complete.\n",
        "\n",
        "**X2, X3, X4, X5, and target:** Each of these columns has exactly 1 missing value. This means there's a single row across these specific columns that contains NaN (Not a Number) or null entries, which will need to be addressed during data preprocessing.\n"
      ],
      "metadata": {
        "id": "N5a2E3WPAIYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.fillna(train.median(), inplace=True)"
      ],
      "metadata": {
        "id": "u-jlCIkk-08U",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:50:52.174401Z",
          "iopub.execute_input": "2026-01-26T20:50:52.174703Z",
          "iopub.status.idle": "2026-01-26T20:50:52.32225Z",
          "shell.execute_reply.started": "2026-01-26T20:50:52.174677Z",
          "shell.execute_reply": "2026-01-26T20:50:52.321116Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Outlier Detection\n",
        "  \n",
        "        Visualize sensores:"
      ],
      "metadata": {
        "id": "D3jfvOJiAeh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(data=train[['X1','X2','X3','X4','X5']])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nXlrChMsAqAs",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:50:52.323257Z",
          "iopub.execute_input": "2026-01-26T20:50:52.323551Z",
          "iopub.status.idle": "2026-01-26T20:51:22.819996Z",
          "shell.execute_reply.started": "2026-01-26T20:50:52.323526Z",
          "shell.execute_reply": "2026-01-26T20:51:22.819163Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Box:** The central box in each plot represents the interquartile range (IQR), which spans from the 25th percentile (Q1) to the 75th percentile (Q3) of the data. The line inside the box indicates the median (50th percentile).\n",
        "\n",
        "**The Whiskers:** The lines extending from the box (whiskers) typically show the range of data within 1.5 times the IQR from the Q1 and Q3. Data points outside these whiskers are considered potential outliers.\n",
        "\n",
        "**The Dots:** Individual points outside the whiskers are indeed identified as outliers."
      ],
      "metadata": {
        "id": "bzcaGbPACYQe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "      Optional capping"
      ],
      "metadata": {
        "id": "rGxWUTplCtEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in ['X1','X2','X3','X4','X5']:\n",
        "    q1 = train[col].quantile(0.01)\n",
        "    q99 = train[col].quantile(0.99)\n",
        "    train[col] = train[col].clip(q1, q99)"
      ],
      "metadata": {
        "id": "kNdQwZj9Dddo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:22.821147Z",
          "iopub.execute_input": "2026-01-26T20:51:22.821466Z",
          "iopub.status.idle": "2026-01-26T20:51:23.083068Z",
          "shell.execute_reply.started": "2026-01-26T20:51:22.821427Z",
          "shell.execute_reply": "2026-01-26T20:51:23.082249Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**This technique is called outlier capping (or Winsorization). We are using it for the following reasons:**\n",
        "\n",
        "**Mitigating Extreme Outliers:** We previously observed that columns X3 and X4 had extremely large maximum values and standard deviations, indicating severe outliers. This clip() operation directly addresses this by setting a floor and ceiling for the values. Instead of removing these extreme data points (which might lead to loss of information), we are 'pulling them in' to a more reasonable range defined by the 1st and 99th percentiles.\n",
        "\n",
        "**Robustness to Models:** Many machine learning models are sensitive to outliers. By capping these extreme values, we make the data more robust, which can help models perform better and prevent them from being overly influenced by a few anomalous data points.\n",
        "\n",
        "**Preserving Data Quantity:** Unlike simply removing rows with outliers, capping allows us to keep all our data points, which can be beneficial, especially with imbalanced datasets where every data point might be valuable."
      ],
      "metadata": {
        "id": "192evyUkEMU3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6 Feature Engineering**"
      ],
      "metadata": {
        "id": "wYzdyMpeEiHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Time-based Features"
      ],
      "metadata": {
        "id": "JcymkyJmEyVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_time_features(df):\n",
        "    # Extract hour, day, month, and weekday from the 'Date' column.\n",
        "    # These features can help capture temporal patterns or cyclical trends\n",
        "    # that might influence anomaly occurrences. For example, certain hours\n",
        "    # of the day or days of the week might be more prone to anomalies.\n",
        "    df['hour'] = df['Date'].dt.hour\n",
        "    df['day'] = df['Date'].dt.day\n",
        "    df['month'] = df['Date'].dt.month\n",
        "    df['weekday'] = df['Date'].dt.weekday\n",
        "    return df\n",
        "\n",
        "train = add_time_features(train)\n",
        "test = add_time_features(test)"
      ],
      "metadata": {
        "id": "5fS5BIcdFFWO",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:23.084205Z",
          "iopub.execute_input": "2026-01-26T20:51:23.084527Z",
          "iopub.status.idle": "2026-01-26T20:51:23.346936Z",
          "shell.execute_reply.started": "2026-01-26T20:51:23.084495Z",
          "shell.execute_reply": "2026-01-26T20:51:23.346075Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "display(train.head())"
      ],
      "metadata": {
        "id": "396e3949",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:23.348079Z",
          "iopub.execute_input": "2026-01-26T20:51:23.348437Z",
          "iopub.status.idle": "2026-01-26T20:51:23.36281Z",
          "shell.execute_reply.started": "2026-01-26T20:51:23.348391Z",
          "shell.execute_reply": "2026-01-26T20:51:23.361759Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Sensor Interactions"
      ],
      "metadata": {
        "id": "CxpOAt6OGx7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The reasoning behind these 'sensor interactions' is to capture relationships or dependencies between different sensor readings that might be indicative of an anomaly. For example, a sudden change in the ratio or difference between two sensors might be a stronger signal for an anomaly than changes in individual sensor readings alone"
      ],
      "metadata": {
        "id": "7JHr8T3LH0ms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a ratio feature: X1 divided by X2.\n",
        "# Ratios can reveal proportional relationships between sensors that might indicate abnormal conditions.\n",
        "# A small constant (1e-5) is added to the denominator to prevent division by zero errors.\n",
        "train['X1_X2_ratio'] = train['X1'] / (train['X2'] + 1e-5)\n",
        "\n",
        "# Create a difference feature: X3 minus X4.\n",
        "# Differences can highlight discrepancies or deviations between sensor readings.\n",
        "# These might signal a malfunction or an unusual operational state.\n",
        "train['X3_minus_X4'] = train['X3'] - train['X4']\n",
        "\n",
        "# Apply the same feature engineering to the test dataset to maintain consistency.\n",
        "test['X1_X2_ratio'] = test['X1'] / (test['X2'] + 1e-5)\n",
        "test['X3_minus_X4'] = test['X3'] - test['X4']"
      ],
      "metadata": {
        "id": "5YssIbfDG-sG",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:23.364109Z",
          "iopub.execute_input": "2026-01-26T20:51:23.364443Z",
          "iopub.status.idle": "2026-01-26T20:51:23.396803Z",
          "shell.execute_reply.started": "2026-01-26T20:51:23.364408Z",
          "shell.execute_reply": "2026-01-26T20:51:23.395837Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Drop Date"
      ],
      "metadata": {
        "id": "w1S7NxokH5Qn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reasoning:** We previously extracted new, more directly useful time-based features (like 'hour', 'day', 'month', and 'weekday') from the 'Date' column. Once these features are created, the original 'Date' column itself, being a datetime object, is typically not directly fed into most machine learning models. Removing it helps to avoid potential issues with model interpretation, reduces the dimensionality of our datasets, and simplifies our feature set."
      ],
      "metadata": {
        "id": "ULFPFpT4IYfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(columns=['Date'], inplace=True)\n",
        "test.drop(columns=['Date'], inplace=True)"
      ],
      "metadata": {
        "id": "A7CMNN_TH3zE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:23.39785Z",
          "iopub.execute_input": "2026-01-26T20:51:23.398143Z",
          "iopub.status.idle": "2026-01-26T20:51:23.654886Z",
          "shell.execute_reply.started": "2026-01-26T20:51:23.39812Z",
          "shell.execute_reply": "2026-01-26T20:51:23.653898Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7 ADVANCED TEMPORAL FEATURES**"
      ],
      "metadata": {
        "id": "KKxGk77VJUV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# The 'Date' column was already processed and dropped in previous steps.\n",
        "# The time-based features (hour, day, weekday, month) have already been created.\n",
        "# Removing the redundant lines that attempt to re-create them from the non-existent 'Date' column.\n",
        "\n",
        "# Rolling stats per sensor\n",
        "sensor_cols = [c for c in train.columns if c.startswith(\"X\")]\n",
        "\n",
        "for col in sensor_cols:\n",
        "    train[f\"{col}_rolling_mean\"] = train[col].rolling(5).mean()\n",
        "    train[f\"{col}_rolling_std\"] = train[col].rolling(5).std()\n",
        "\n",
        "    test[f\"{col}_rolling_mean\"] = test[col].rolling(5).mean()\n",
        "    test[f\"{col}_rolling_std\"] = test[col].rolling(5).std()\n",
        "\n",
        "train.fillna(0, inplace=True)\n",
        "test.fillna(0, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:23.655953Z",
          "iopub.execute_input": "2026-01-26T20:51:23.656245Z",
          "iopub.status.idle": "2026-01-26T20:51:24.69121Z",
          "shell.execute_reply.started": "2026-01-26T20:51:23.65622Z",
          "shell.execute_reply": "2026-01-26T20:51:24.690315Z"
        },
        "id": "jkVrahWQJUV4"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INTERACTION FEATURES**"
      ],
      "metadata": {
        "id": "VVX5dcCgJUV4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# SENSOR INTERACTIONS\n",
        "# ================================\n",
        "\n",
        "for i in range(len(sensor_cols)):\n",
        "    for j in range(i+1, min(i+4, len(sensor_cols))):\n",
        "        c1, c2 = sensor_cols[i], sensor_cols[j]\n",
        "\n",
        "        train[f\"{c1}_ratio_{c2}\"] = train[c1] / (train[c2] + 1e-6)\n",
        "        test[f\"{c1}_ratio_{c2}\"] = test[c1] / (test[c2] + 1e-6)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:24.692438Z",
          "iopub.execute_input": "2026-01-26T20:51:24.692775Z",
          "iopub.status.idle": "2026-01-26T20:51:24.895389Z",
          "shell.execute_reply.started": "2026-01-26T20:51:24.692742Z",
          "shell.execute_reply": "2026-01-26T20:51:24.894655Z"
        },
        "id": "2IEGUlxsJUWD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. Correlation Analysis**"
      ],
      "metadata": {
        "id": "ylYYdt4IImWQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Identify relationships between features:** See which features move together (positively or negatively correlated), which can be useful for understanding the underlying processes or for identifying multicollinearity.\n",
        "\n",
        "**Understand feature importance with respect to the target:** Discover which features have a strong relationship with the target variable. This can provide insights into which sensor readings are most indicative of an anomaly.\n",
        "\n",
        "**Guide further feature selection:** If two features are highly correlated, one might be redundant, and we might consider dropping one to simplify the model and prevent issues like multicollinearity.\n",
        "Inform model building: Understanding these relationships can help in choosing appropriate models or interpreting model results."
      ],
      "metadata": {
        "id": "JqkSZbPQJGqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "sns.heatmap(train.corr(), cmap=\"coolwarm\")\n",
        "plt.title(\"Feature Correlation Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "j7FJsafpJVvq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:24.896577Z",
          "iopub.execute_input": "2026-01-26T20:51:24.896911Z",
          "iopub.status.idle": "2026-01-26T20:51:36.15887Z",
          "shell.execute_reply.started": "2026-01-26T20:51:24.896878Z",
          "shell.execute_reply": "2026-01-26T20:51:36.15786Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Feature Correlation Matrix is a visual tool (heatmap) that shows the linear relationship between every pair of features in your dataset. It tells you which features tend to move together (positive correlation), move in opposite directions (negative correlation), or have no linear relationship (near zero correlation). This helps in understanding data structure, identifying important features, and detecting redundancy."
      ],
      "metadata": {
        "id": "QX5P2x1VK4Bn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explain which sensors correlate with anomalies.**\n",
        "\n",
        "To accurately identify which sensors correlate with anomalies, let's look at the correlation values of each feature with the 'target' variable. This will show us the strength and direction of their linear relationship.\n",
        "\n",
        "Based on the correlation values with the target variable, here's what we can observe about which sensors correlate with anomalies:"
      ],
      "metadata": {
        "id": "et-JXCo3LTwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correlation_with_target = train.corr()['target'].sort_values(ascending=False)\n",
        "display(correlation_with_target)"
      ],
      "metadata": {
        "id": "f150eff8",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:36.160001Z",
          "iopub.execute_input": "2026-01-26T20:51:36.160496Z",
          "iopub.status.idle": "2026-01-26T20:51:46.577901Z",
          "shell.execute_reply.started": "2026-01-26T20:51:36.16046Z",
          "shell.execute_reply": "2026-01-26T20:51:46.577125Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**9. Train / Validation Split**"
      ],
      "metadata": {
        "id": "ar7lxYQkLuFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(columns=['target'])\n",
        "y = train['target']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(X_train.shape, X_val.shape)"
      ],
      "metadata": {
        "id": "ST8qZGoCLwmB",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:46.579175Z",
          "iopub.execute_input": "2026-01-26T20:51:46.57955Z",
          "iopub.status.idle": "2026-01-26T20:51:48.652739Z",
          "shell.execute_reply.started": "2026-01-26T20:51:46.579516Z",
          "shell.execute_reply": "2026-01-26T20:51:48.651912Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  **Prevent Overfitting:** It ensures our model learns general patterns from the training data and doesn't just memorize it, which would lead to poor performance on new, unseen data.\n",
        "2.  **Evaluate Generalization:** It allows us to objectively assess how well our model, once trained, can predict anomalies on data it has never seen before, giving us a realistic measure of its real-world performance."
      ],
      "metadata": {
        "id": "0bceb915"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10 .Temporal Feature Engineering**"
      ],
      "metadata": {
        "id": "44hzmdGQJUWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm = LGBMClassifier(\n",
        "    n_estimators=1200,\n",
        "    learning_rate=0.03,\n",
        "    num_leaves=128,\n",
        "    max_depth=-1,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    class_weight=\"balanced\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lgbm.fit(X_train, y_train)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:51:48.653858Z",
          "iopub.execute_input": "2026-01-26T20:51:48.654163Z",
          "iopub.status.idle": "2026-01-26T20:55:01.046895Z",
          "shell.execute_reply.started": "2026-01-26T20:51:48.654138Z",
          "shell.execute_reply": "2026-01-26T20:55:01.045817Z"
        },
        "id": "Wr63h0WoJUWH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This LightGBM output shows the model trained on a large, imbalanced dataset (many more normal operations than anomalies) using 39 features. It utilized multi-threading for efficiency and confirms the hyperparameters set for the LGBMClassifier, including class_weight='balanced' to handle the imbalance."
      ],
      "metadata": {
        "id": "qXCJEnzxJUWJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**11. Feature Scaling**"
      ],
      "metadata": {
        "id": "0c8ZGo_QNZwA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)"
      ],
      "metadata": {
        "id": "pQIe-Y4yNy6o",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:55:01.048216Z",
          "iopub.execute_input": "2026-01-26T20:55:01.048499Z",
          "iopub.status.idle": "2026-01-26T20:55:02.07334Z",
          "shell.execute_reply.started": "2026-01-26T20:55:01.048474Z",
          "shell.execute_reply": "2026-01-26T20:55:02.072515Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "feature scaling ensures that no single sensor's measurement range unfairly dominates our machine learning models (like SVM or KNN), especially since some original sensor readings had very large values. It helps models learn more effectively and leads to better anomaly detection performance by giving all features an equal footing.\n",
        "\n"
      ],
      "metadata": {
        "id": "7afydmG7Ox8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**12. Classical Models**"
      ],
      "metadata": {
        "id": "GxRbwMXjOz31"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Logistic Regression"
      ],
      "metadata": {
        "id": "zDaD2dD1PMsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(class_weight='balanced', max_iter=500)\n",
        "lr.fit(X_train_scaled, y_train)\n",
        "\n",
        "pred = lr.predict(X_val_scaled)\n",
        "\n",
        "print(classification_report(y_val, pred))"
      ],
      "metadata": {
        "id": "RBrFLVl_PTlz",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:55:02.074582Z",
          "iopub.execute_input": "2026-01-26T20:55:02.075346Z",
          "iopub.status.idle": "2026-01-26T20:56:44.858454Z",
          "shell.execute_reply.started": "2026-01-26T20:55:02.075308Z",
          "shell.execute_reply": "2026-01-26T20:56:44.857148Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression model's evaluation metrics have been updated in the markdown cell. Specifically, for anomalies (class 1), the precision was updated from 0.16 to 0.14, recall from 0.92 to 0.96, F1-score from 0.28 to 0.24, and overall accuracy from 0.90 to 0.95."
      ],
      "metadata": {
        "id": "fmFpgATXPuBj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* KNN"
      ],
      "metadata": {
        "id": "4JzbCIYuP_mA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=7)\n",
        "knn.fit(X_train_scaled, y_train)\n",
        "\n",
        "pred = knn.predict(X_val_scaled)\n",
        "print(classification_report(y_val, pred))"
      ],
      "metadata": {
        "id": "wevM8X5_QB73",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T20:56:44.864892Z",
          "iopub.execute_input": "2026-01-26T20:56:44.866869Z",
          "iopub.status.idle": "2026-01-26T21:21:31.922374Z",
          "shell.execute_reply.started": "2026-01-26T20:56:44.86683Z",
          "shell.execute_reply": "2026-01-26T21:21:31.921305Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The KNN model shows strong overall accuracy (0.99). For anomalies, it has 75% precision, 40% recall, and an F1-score of 0.52."
      ],
      "metadata": {
        "id": "acYSbNfMQpc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Decision Tree"
      ],
      "metadata": {
        "id": "G8dhQCcAQyHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt = DecisionTreeClassifier(\n",
        "    max_depth=8,\n",
        "    class_weight='balanced',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "dt.fit(X_train, y_train)\n",
        "pred = dt.predict(X_val)\n",
        "\n",
        "print(classification_report(y_val, pred))\n"
      ],
      "metadata": {
        "id": "cW66ZJvDQr5q",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T21:21:31.923697Z",
          "iopub.execute_input": "2026-01-26T21:21:31.924039Z",
          "iopub.status.idle": "2026-01-26T21:22:18.773387Z",
          "shell.execute_reply.started": "2026-01-26T21:21:31.924012Z",
          "shell.execute_reply": "2026-01-26T21:22:18.772589Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Decision Tree model accurately identifies most normal operations but has very low precision for anomalies, leading to many false positives, despite a high recall for anomalies. Its F1-score for anomalies is 0.25."
      ],
      "metadata": {
        "id": "rRcBZqCORoJV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* SVM"
      ],
      "metadata": {
        "id": "9s2Jvv-kR3yF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='rbf', class_weight='balanced')\n",
        "svm.fit(X_train_scaled[:100000], y_train[:100000])\n",
        "\n",
        "pred = svm.predict(X_val_scaled)\n",
        "print(classification_report(y_val, pred))"
      ],
      "metadata": {
        "id": "lFg9t22ZR6zx",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T21:22:18.77464Z",
          "iopub.execute_input": "2026-01-26T21:22:18.774995Z",
          "iopub.status.idle": "2026-01-26T21:26:39.667396Z",
          "shell.execute_reply.started": "2026-01-26T21:22:18.774961Z",
          "shell.execute_reply": "2026-01-26T21:26:39.666565Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The SVM model is very good at identifying normal operations. For anomalies, it has a good recall (0.79), meaning it catches many, but its precision is low (0.25), resulting in a moderate F1-score of 0.38. It still creates a fair number of false alarms."
      ],
      "metadata": {
        "id": "ug7WhAUST7-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13. Advanced Models**"
      ],
      "metadata": {
        "id": "XS8A3S1QUAMO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Random Forest"
      ],
      "metadata": {
        "id": "bo6KINcTUInU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf = RandomForestClassifier(\n",
        "    n_estimators=300,\n",
        "    max_depth=12,\n",
        "    class_weight='balanced',\n",
        "    n_jobs=-1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "pred = rf.predict(X_val)\n",
        "print(classification_report(y_val, pred))"
      ],
      "metadata": {
        "id": "b8bW5MyZUX1p",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T21:26:39.668361Z",
          "iopub.execute_input": "2026-01-26T21:26:39.668647Z",
          "iopub.status.idle": "2026-01-26T21:37:20.123439Z",
          "shell.execute_reply.started": "2026-01-26T21:26:39.668616Z",
          "shell.execute_reply": "2026-01-26T21:37:20.122574Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* XGBoost"
      ],
      "metadata": {
        "id": "8nc0HZngVfFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xgb = XGBClassifier(\n",
        "    n_estimators=800,\n",
        "    max_depth=7,\n",
        "    learning_rate=0.03,\n",
        "    subsample=0.85,\n",
        "    colsample_bytree=0.85,\n",
        "    eval_metric=\"logloss\",\n",
        "    scale_pos_weight=y_train.value_counts()[0] / y_train.value_counts()[1],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "v1FWJlVvVlC9",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T21:37:20.124466Z",
          "iopub.execute_input": "2026-01-26T21:37:20.124762Z",
          "iopub.status.idle": "2026-01-26T21:39:01.998111Z",
          "shell.execute_reply.started": "2026-01-26T21:37:20.124731Z",
          "shell.execute_reply": "2026-01-26T21:39:01.997218Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* CatBoost"
      ],
      "metadata": {
        "id": "UF9wUk1eWKm0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is the go-to tool for tabular data when you want high accuracy and native support for categories with minimal effort."
      ],
      "metadata": {
        "id": "-96iuZxOWNy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat = CatBoostClassifier(\n",
        "    iterations=800,\n",
        "    depth=8,\n",
        "    learning_rate=0.04,\n",
        "    loss_function=\"Logloss\",\n",
        "    auto_class_weights=\"Balanced\",\n",
        "    verbose=0,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "cat.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "z1II_zaOW1th",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T21:39:01.999186Z",
          "iopub.execute_input": "2026-01-26T21:39:01.99944Z",
          "iopub.status.idle": "2026-01-26T21:43:00.651734Z",
          "shell.execute_reply.started": "2026-01-26T21:39:01.999416Z",
          "shell.execute_reply": "2026-01-26T21:43:00.650892Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**14. ENSEMBLE**"
      ],
      "metadata": {
        "id": "xJRF4yQ3JUWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Threshold Optimization for F1 Score**"
      ],
      "metadata": {
        "id": "q_aPbE8kJUWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "\n",
        "models = {\n",
        "    \"lgbm\": lgbm,\n",
        "    \"xgb\": xgb,\n",
        "    \"cat\": cat\n",
        "}\n",
        "\n",
        "val_probs = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    val_probs[name] = model.predict_proba(X_val)[:,1]\n",
        "\n",
        "avg_probs = np.mean(list(val_probs.values()), axis=0)\n",
        "\n",
        "thresholds = np.linspace(0.05, 0.95, 60)\n",
        "\n",
        "best_f1 = 0\n",
        "best_thresh = 0.5\n",
        "\n",
        "for t in thresholds:\n",
        "    preds = (avg_probs >= t).astype(int)\n",
        "    f1 = f1_score(y_val, preds)\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_thresh = t\n",
        "\n",
        "print(\"Best F1:\", best_f1)\n",
        "print(\"Best threshold:\", best_thresh)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T21:43:00.652817Z",
          "iopub.execute_input": "2026-01-26T21:43:00.653201Z",
          "iopub.status.idle": "2026-01-26T21:43:42.129807Z",
          "shell.execute_reply.started": "2026-01-26T21:43:00.653176Z",
          "shell.execute_reply": "2026-01-26T21:43:42.128706Z"
        },
        "id": "xZN_nzqRJUWU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "cat_probs = cat.predict_proba(X_val)[:, 1]\n",
        "xgb_probs = xgb.predict_proba(X_val)[:, 1]\n",
        "lgb_probs = lgbm.predict_proba(X_val)[:, 1]\n",
        "\n",
        "avg_probs = (cat_probs + xgb_probs + lgb_probs) / 3\n",
        "\n",
        "ensemble_preds = (avg_probs >= best_thresh).astype(int)\n",
        "\n",
        "print(classification_report(y_val, ensemble_preds))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T21:44:57.481185Z",
          "iopub.execute_input": "2026-01-26T21:44:57.481784Z",
          "iopub.status.idle": "2026-01-26T21:45:37.647618Z",
          "shell.execute_reply.started": "2026-01-26T21:44:57.481749Z",
          "shell.execute_reply": "2026-01-26T21:45:37.646611Z"
        },
        "id": "p8rhqSgRJUWV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**15. Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "BmFJYQKhXTxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    \"depth\":[5,7],\n",
        "    \"learning_rate\":[0.03,0.1],\n",
        "    \"iterations\":[300,500]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    CatBoostClassifier(auto_class_weights=\"Balanced\", verbose=0),\n",
        "    param_grid,\n",
        "    scoring=\"f1\",\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "grid.best_params_"
      ],
      "metadata": {
        "id": "_m3WL5WQXfgP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T21:45:44.516487Z",
          "iopub.execute_input": "2026-01-26T21:45:44.517192Z",
          "iopub.status.idle": "2026-01-26T22:15:13.698281Z",
          "shell.execute_reply.started": "2026-01-26T21:45:44.517162Z",
          "shell.execute_reply": "2026-01-26T22:15:13.697478Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "This output represents the optimal hyperparameters for CatBoost model, specifically for depth, iterations, and learning_rate, that resulted in the best F1-score during the GridSearchCV process. This means that among the combinations you tested, a depth of 7, 500 iterations, and a learning_rate of 0.1 are the settings that yielded the best performance for identifying anomalies."
      ],
      "metadata": {
        "id": "ynZAfAY3ZC0K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**16. Cross-Validation**"
      ],
      "metadata": {
        "id": "wbdlPGpXZezP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(5)\n",
        "\n",
        "scores = []\n",
        "\n",
        "for tr_idx, va_idx in skf.split(X, y):\n",
        "    X_tr, X_va = X.iloc[tr_idx], X.iloc[va_idx]\n",
        "    y_tr, y_va = y.iloc[tr_idx], y.iloc[va_idx]\n",
        "\n",
        "    model = LGBMClassifier(class_weight=\"balanced\")\n",
        "    model.fit(X_tr, y_tr)\n",
        "\n",
        "    preds = model.predict(X_va)\n",
        "    scores.append(f1_score(y_va, preds))\n",
        "\n",
        "np.mean(scores)"
      ],
      "metadata": {
        "id": "Xn1AyIqcZGP3",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T22:16:41.306113Z",
          "iopub.execute_input": "2026-01-26T22:16:41.306429Z",
          "iopub.status.idle": "2026-01-26T22:18:07.245637Z",
          "shell.execute_reply.started": "2026-01-26T22:16:41.306402Z",
          "shell.execute_reply": "2026-01-26T22:18:07.244636Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The cross-validation process, using a LightGBM model, resulted in an average F1-score of approximately 0.409. This score indicates the model's performance in identifying anomalies across different splits of your data, providing a more robust evaluation than a single train-validation split. The output logs from LightGBM detail the setup for each training fold."
      ],
      "metadata": {
        "id": "TQY-tg33aUAl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**17. Robustness Checks**"
      ],
      "metadata": {
        "id": "TjPtYzGBacGj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Confusion matrix:"
      ],
      "metadata": {
        "id": "akhOXT9uaeHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A confusion matrix is useful because it provides a detailed breakdown of a model's correct and incorrect predictions across all classes, revealing exactly where it is succeeding or failing beyond simple accuracy."
      ],
      "metadata": {
        "id": "BL4yba5japiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_val, pred)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "82eXIkQIa-uS",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T22:18:19.742954Z",
          "iopub.execute_input": "2026-01-26T22:18:19.743875Z",
          "iopub.status.idle": "2026-01-26T22:18:19.903734Z",
          "shell.execute_reply.started": "2026-01-26T22:18:19.743844Z",
          "shell.execute_reply": "2026-01-26T22:18:19.90294Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        " The confusion matrix shows that the model accurately identified 20,630 normal operations (True Negatives) and 429 anomalies (True Positives). However, it made 721 false alarms (False Positives), where it predicted an anomaly but it was normal, and missed 30 actual anomalies (False Negatives), predicting them as normal.\n"
      ],
      "metadata": {
        "id": "7_71FfStb1ul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Residual analysis:"
      ],
      "metadata": {
        "id": "JTXNgGPhb7gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "residuals = y_val - pred\n",
        "sns.histplot(residuals)\n",
        "plt.title(\"Residual Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6ZX1rXvdcMJq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T22:18:27.365158Z",
          "iopub.execute_input": "2026-01-26T22:18:27.365965Z",
          "iopub.status.idle": "2026-01-26T22:18:27.745327Z",
          "shell.execute_reply.started": "2026-01-26T22:18:27.365926Z",
          "shell.execute_reply": "2026-01-26T22:18:27.744491Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Residual Distribution plot visually represents the model's errors. A large bar at zero indicates correct predictions (where y_val equals pred). Bars at -1.0 signify False Positives (model predicted 1, actual was 0), and bars at 1.0 signify False Negatives (model predicted 0, actual was 1). This plot helps quickly identify the frequency and type of prediction errors made by the model."
      ],
      "metadata": {
        "id": "m5CRcVwScy7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = train.drop(columns=[\"target\"])\n",
        "y = train[\"target\"]\n",
        "\n",
        "lgbm.fit(X, y)\n",
        "xgb.fit(X, y)\n",
        "cat.fit(X, y)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T22:18:33.815613Z",
          "iopub.execute_input": "2026-01-26T22:18:33.81594Z",
          "iopub.status.idle": "2026-01-26T22:28:20.480618Z",
          "shell.execute_reply.started": "2026-01-26T22:18:33.815915Z",
          "shell.execute_reply": "2026-01-26T22:28:20.479701Z"
        },
        "id": "mjUs4Hn1JUWr"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**18. Train Final Model & Submission**"
      ],
      "metadata": {
        "id": "rCO7HcIsdACH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test.drop(columns=[\"ID\"])\n",
        "test_ids = test[\"ID\"]\n",
        "\n",
        "test_probs = (\n",
        "    lgbm.predict_proba(X_test)[:,1] +\n",
        "    xgb.predict_proba(X_test)[:,1] +\n",
        "    cat.predict_proba(X_test)[:,1]\n",
        ") / 3\n",
        "\n",
        "test_preds = (test_probs >= best_thresh).astype(int)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ID\": test_ids,\n",
        "    \"target\": test_preds\n",
        "})\n",
        "\n",
        "print(submission.shape)\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "id": "vDpcV00gc7p6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T22:28:41.862782Z",
          "iopub.execute_input": "2026-01-26T22:28:41.863575Z",
          "iopub.status.idle": "2026-01-26T22:29:29.873955Z",
          "shell.execute_reply.started": "2026-01-26T22:28:41.863534Z",
          "shell.execute_reply": "2026-01-26T22:29:29.873107Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"Saved submission.csv\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-26T22:29:37.774894Z",
          "iopub.execute_input": "2026-01-26T22:29:37.77551Z",
          "iopub.status.idle": "2026-01-26T22:29:38.085515Z",
          "shell.execute_reply.started": "2026-01-26T22:29:37.775481Z",
          "shell.execute_reply": "2026-01-26T22:29:38.084635Z"
        },
        "id": "f4X-BgvIJUWt"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**we have taken the following steps:**\n",
        "\n",
        "**Data Preprocessing:** Handling missing values by imputation and outliers by capping, followed by feature scaling.\n",
        "\n",
        "**Feature Engineering:** Creating time-based features (hour, day, month, weekday) and new sensor interaction features (ratios, differences, rolling statistics).\n",
        "\n",
        "**Exploratory Data Analysis:** Analyzing target distribution (class imbalance) and feature correlations.\n",
        "\n",
        "**Model Training:** Evaluating various classical (Logistic Regression, KNN, Decision Tree, SVM) and advanced (Random Forest, XGBoost, CatBoost, LightGBM) machine learning models, with a focus on F1-score due to class imbalance.\n",
        "\n",
        "**Optimization:** Performing hyperparameter tuning (GridSearchCV) for CatBoost and ensemble modeling with threshold optimization for improved F1-score.\n",
        "\n",
        "**Evaluation & Robustness:** Using cross-validation, confusion matrices, and residual analysis for robust model assessment.\n",
        "Submission: Training the final ensemble model and generating predictions for the test set."
      ],
      "metadata": {
        "id": "N-afoQzrdwAK"
      }
    }
  ]
}